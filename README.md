# awesome-papers-iclr
Some awesome papers in ICLR 2024.
## **Pretraining / Foundation Models**

| #    | Title                                                        |
| ---- | ------------------------------------------------------------ |
| 1    | Self-Guided  Masked Autoencoders for Domain-Agnostic Self-Supervised  Learning |
| 2    | Views Can Be Deceiving: Improved SSL Through Feature Space  Augmentation (Spotlight) |
| 3    | Improved  baselines for vision-language pre-training [VLP]   |
| 4    | From  Molecules to Materials:  Pre-training Large Generalizable Models for Atomic Property Prediction  [Foundation models] |
| 5    | Emu:  Generative Pretraining in Multimodality [MLLM]         |
| 6    | BioBridge:  Bridging Biomedical  Foundation Models via Knowledge Graphs [Foundation models] |
| 7    | Non-negative  Contrastive Learning                           |
| 8    | Mind Your Augmentation: The Key to  Decoupling Dense Self-Supervised Learning |
| 9    | Self-supervised  Representation Learning from Random Data Projectors |
| 10   | COSA:  Concatenated Sample Pretrained Vision-Language Foundation Model [VLP] |
| 11   | Structuring  Representation Geometry with Rotationally Equivariant Contrastive Learning |
| 12   | Hybrid  Distillation: Connecting Masked Autoencoders with Contrastive Learners |
| 13   | CoBIT:  A Contrastive  Bi-directional Image-Text Generation Model |
| 14   | REBAR: Retrieval-Based Reconstruction  for Time-series  Contrastive Learning |
| 15   | Pre-training with Random Orthogonal  Projection Image Modeling (Spotlight) |
| 16   | Towards LLM4QPE: Unsupervised  Pretraining of Quantum  Property Estimation and A Benchmark  [Foundation  models] |
| 17   | Unified Language-Vision Pretraining in LLM with Dynamic Discrete  Visual Tokenization [VLP] |
| 18   | Think before you speak: Training Language Models With Pause Tokens [LLM] |
| 19   | Self-supervised Pocket Pretraining via Protein Fragment-Surroundings Alignment  [Foundation models] |
| 20   | LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic  Alignment [MLLM] |
| 21   | UniTabE: A Universal Pretraining  Protocol for Tabular Foundation Model in Data Science [Foundation models] |
| 22   | On the Provable Advantage of  Unsupervised Pretraining       |
| 23   | Neuroformer: Multimodal and Multitask Generative  Pretraining for Brain  Data [Foundation  models, MLLM] |
| 24   | Detecting Pretraining Data from Large Language Models [LLM]  |
| 25   | Transformers as Decision Makers:  Provable In-Context Reinforcement Learning via Supervised Pretraining |
| 26   | Sophia: A Scalable Stochastic  Second-order Optimizer for Language Model Pre-training  [LLM] |
| 27   | Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation |
| 28   | Sliced Denoising: A Physics-Informed Molecular Pre-Training Method  [Foundation models] |
| 29   | CALICO: Self-Supervised Camera-LiDAR Contrastive Pre-training for BEV  Perception [Foundation  models] |
| 30   | Fast-ELECTRA for Efficient Pre-training                      |
| 31   | Decoupling Weighing and Selecting for  Integrating Multiple Graph Pre-training Tasks |
| 32   | Pre-training LiDAR-based 3D Object Detectors through Colorization |
| 33   | Pre-training Sequence, Structure,  and Surface Features for Comprehensive Protein Representation Learning  [Foundation models] |
| 34   | Pre-training with Synthetic Data Helps Offline Reinforcement  Learning |
| 35   | CellPLM: Pre-training of Cell Language  Model Beyond Single Cells [Foundation  models] |
| 36   | Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning (Oral) |
| 37   | SNIP: Bridging Mathematical Symbolic and Numeric Realms with  Unified Pre-training (Spotlight)  [Foundation models] |
| 38   | Multi-View Representation is What  You Need for Point-Cloud  Pre-Training [Foundation  models] |
| 39   | Generative Pre-training for Speech with Flow Matching  [Foundation models] |
| 40   | Sheared LLaMA: Accelerating Language Model Pre-training via  Structured Pruning |
| 41   | Masked Structural Growth for 2x Faster Language Model Pre-training |
| 42   | Pre-Training and Fine-Tuning  Generative Flow Networks (Spotlight) |
| 43   | Understanding and Mitigating the Label Noise in Pre-training on Downstream  Tasks (Spotlight) |
| 44   | Remote Sensing Vision-Language Foundation  Models without Annotations via Ground Remote Alignment  [Foundation models] |

## LLM

| #    | Title                                                        |
| ---- | ------------------------------------------------------------ |
| 1    | RAIN:  Your Language Models Can Align  Themselves without Finetuning |
| 2    | To the Cutoff... and Beyond? A  Longitudinal Perspective on LLM Data Contamination |
| 3    | Model Tells You What to Discard:  Adaptive KV Cache Compression for  LLMs (Oral) |
| 4    | DreamLLM: Synergistic Multimodal Comprehension and Creation (Spotlight) |
| 5    | Time-LLM: Time Series Forecasting by Reprogramming  Large Language Models |
| 6    | Time Travel in LLMs: Tracing Data Contamination in Large Language Models |
| 7    | TEST: Text Prototype Aligned Embedding  to Activate LLM's Ability for Time Series |
| 8    | AntGPT: Can Large Language Models Help  Long-term Action Anticipation from Videos? |
| 9    | OpenChat: Advancing Open-source Language Models with  Mixed-Quality Data |
| 10   | LMSYS-Chat-1M: A Large-Scale  Real-World LLM Conversation Dataset (Spotlight) |
| 11   | MiniLLM: Knowledge Distillation of Large Language Models     |
| 12   | Large Language Models Cannot  Self-Correct Reasoning  Yet    |
| 13   | GeoLLM: Extracting Geospatial Knowledge from Large Language Models |
| 14   | LLM Augmented LLMs: Expanding Capabilities  through Composition |
| 15   | Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author  Prompt Editing |
| 16   | What's  In My Big Data? (Spotlight)                          |
| 17   | Language Modeling Is Compression                             |
| 18   | Linearity of Relation Decoding in  Transformer Language Models (Spotlight) |
| 19   | PoSE: Efficient Context Window Extension of  LLMs via Positional Skip-wise Training |
| 20   | CRAFT: Customizing LLMs by Creating and  Retrieving from Specialized Toolsets |
| 21   | AgentBench: Evaluating LLMs as Agents                        |
| 22   | LLM-Assisted Code Cleaning For Training  Accurate Code  Generators |
| 23   | MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback |
| 24   | BooookScore: A systematic exploration of book-length summarization in the era of LLMs (Oral) |
| 25   | At Which Training Stage Does Code  Data Help LLMs Reasoning?  (Spotlight) |
| 26   | SmartPlay : A Benchmark for LLMs as Intelligent Agents       |
| 27   | LLMs Meet VLMs: Boost Open Vocabulary Object  Detection with  Fine-grained Descriptors |
| 28   | MathCoder: Seamless Code Integration in LLMs for  Enhanced Mathematical  Reasoning |
| 29   | Knowledge Card: Filling LLMs' Knowledge  Gaps with Plug-in Specialized Language Models (Oral) |
| 30   | Label-free Node Classification on  Graphs with Large Language Models (LLMs) |
| 31   | Understanding the Effects of RLHF on  LLM Generalisation and Diversity |
| 32   | Hierarchical Context Merging: Better Long Context Understanding for Pre-trained LLMs |
| 33   | SpQR: A Sparse-Quantized  Representation for Near-Lossless LLM Weight Compression |
| 34   | KITAB: Evaluating LLMs on Constraint  Satisfaction for Information Retrieval |
| 35   | Spoken Question Answering and  Speech Continuation Using  Spectrogram-Powered LLM |
| 36   | ChatEval: Towards Better LLM-based Evaluators  through Multi-Agent  Debate |
| 37   | LLM-grounded Video Diffusion Models                          |
| 38   | ToolLLM: Facilitating Large Language  Models to Master 16000+ Real-world APIs |
| 39   | SuRe: Summarizing Retrievals using  Answer Candidates for Open-domain QA  of LLMs |
| 40   | Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs |
| 41   | Towards Codable Watermarking for Injecting Multi-Bits  Information to LLMs |
| 42   | The Reversal Curse: LLMs trained  on “A is B” fail to learn “B is A” |
| 43   | QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models |
| 44   | PB-LLM: Partially Binarized Large Language Models            |
| 45   | LLMCarbon: Modeling the End-to-End Carbon Footprint of Large Language Models (Oral) |
| 46   | Compressing LLMs: The Truth is Rarely Pure  and Never Simple |
| 47   | SelfCheck: Using LLMs to Zero-Shot Check Their  Own Step-by-Step Reasoning |
| 48   | LLM-CXR: Instruction-Finetuned  LLM for CXR  Image Understanding and Generation |
| 49   | Chain-of-Experts: When LLMs Meet Complex  Operations Research Problems |
| 50   | Hybrid LLM: Cost-Efficient and  Quality-Aware Query Routing  |

## VLM

| #    | Title                                                        |
| ---- | ------------------------------------------------------------ |
| 1    | Steve-Eye: Equipping LLM-based Embodied  Agents with Visual Perception in Open Worlds |
| 2    | Tag2Text: Guiding Vision-Language Model via Image Tagging    |
| 3    | Rephrase, Augment, Reason: Visual  Grounding of Questions for Vision-Language Models |
| 4    | ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models |
| 5    | Overcoming the Pitfalls of Vision-Language Model  Finetuning for OOD Generalization |
| 6    | Measuring Vision-Language STEM Skills  of Neural Models      |
| 7    | Frozen Transformers in Language Models Are Effective  Visual Encoder Layers (Spotlight) |
| 8    | Towards Unified Multi-Modal  Personalization:  Large Vision-Language Models for Generative Recommendation and Beyond |
| 9    | Test-Time Adaptation with CLIP Reward for Zero-Shot  Generalization in Vision-Language Models |
| 10   | Visual Data-Type Understanding  does not emerge from scaling Vision-Language Models |
| 11   | Negative Label Guided OOD Detection with Pretrained Vision-Language  Models (Spotlight) |
| 12   | Nemesis: Normalizing the Soft-prompt Vectors of Vision-Language  Models (Spotlight) |
| 13   | Open-ended VQA benchmarking of Vision-Language models by  exploiting Classification datasets and their semantic hierarchy (Spotlight) |
| 14   | Leveraging Unpaired Data for Vision-Language Generative  Models via  Cycle Consistency (Spotlight) |
| 15   | MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language  Models |
| 16   | Federated  Text-driven Prompt Generation for Vision-Language Models |
| 17   | Vision-Language Models are Zero-Shot Reward Models for Reinforcement Learning |
| 18   | Large Language Models as Automated Aligners for benchmarking Vision-Language  Models |
| 19   | Vision-Language Foundation Models as Effective Robot Imitators |

##  **Efficient Tuning**

| #    | Title                                                        |
| ---- | ------------------------------------------------------------ |
| 1    | AutoLoRa: An Automated Robust Fine-Tuning  Framework         |
| 2    | Convolution  Meets LoRA:  Parameter Efficient Finetuning for Segment Anything Model |
| 3    | The  Expressive Power of Low-Rank  Adaptation                |
| 4    | LQ-LoRA: Low-rank plus Quantized Matrix  Decomposition for Efficient Language Model |
| 5    | Mixture  of LoRA  Experts                                    |
| 6    | ReLoRA: High-Rank Training Through Low-Rank  Updates         |
| 7    | LongLoRA: Efficient Fine-tuning of  Long-Context Large Language Models (Oral) |
| 8    | DataInf: Efficiently Estimating Data Influence  in LoRA-tuned LLMs and Diffusion Models |
| 9    | LLM Blueprint: Enabling Text-to-Image  Generation with Complex and Detailed Prompts |
| 10   | TEMPO: Prompt-based Generative Pre-trained  Transformer for Time Series Forecasting |
| 11   | Consistency-guided  Prompt  Learning for Vision-Language Models |
| 12   | Learning  Semantic Proxies from Visual Prompts  for Parameter-Efficient Fine-Tuning in Deep Metric Learning |
| 13   | DePT:  Decomposed Prompt  Tuning for Parameter-Efficient Fine-tuning |
| 14   | Zero-Shot Continuous Prompt Transfer: Generalizing Task  Semantics Across Language Models |
| 15   | Increasing  Model Capacity for Free: A Simple Strategy for Parameter Efficient  Fine-tuning |
| 16   | Supervised  Knowledge Makes Large Language Models Better In-context  Learners |
| 17   | Get  more for less: Principled Data Selection for Warming Up Fine-Tuning in LLMs |
| 18   | Understanding  In-Context Learning in  Transformers and LLMs by Learning to Learn Discrete Functions (Oral) |
| 19   | MMICL:  Empowering Vision-language Model with Multi-Modal  In-Context Learning |
| 20   | In-Context Learning Learns Label Relationships but  Is Not Conventional Learning |
| 21   | CausalLM is not optimal for in-context learning              |
| 22   | In-context Autoencoder for  Context Compression in  a Large Language Model |
| 23   | The  Cost of Scaling Down Large Language Models: Reducing Model Size Affects  Memory before In-context Learning |
| 24   | MEND:  Meta Demonstration Distillation for Efficient and Effective In-Context Learning |
| 25   | Self-RAG:  Learning to Retrieve, Generate, and  Critique through Self-Reflection |
| 26   | RA-DIT:  Retrieval-Augmented Dual  Instruction Tuning        |
| 27   | RECOMP:  Improving Retrieval-Augmented  LMs with Context Compression and Selective Augmentation |
| 28   | Retrieval-Enhanced  Contrastive Vision-Text Models           |
| 29   | Towards  Few-Shot Adaptation of Foundation Models via Multitask Finetuning |
| 30   | PandaLM:  An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization |
| 31   | How  Many Pretraining Tasks Are Needed for In-Context  Learning of Linear Regression? |
| 32   | Fine-tuning Multimodal LLMs to Follow  Zero-shot Demonstrative Instructions (Spotlight) |
| 33   | Skeleton-of-Thought: Prompting LLMs for Efficient Parallel  Generation |
| 34   | ModuLoRA: Finetuning 2-Bit LLMs on  Consumer GPUs by Integrating with Modular Quantizers |
| 35   | Dynamic Sparse No Training:  Training-Free Fine-tuning for Sparse LLMs |
| 36   | When Scaling Meets LLM Finetuning: The Effect  of Data,  Model and Finetuning Method |
| 37   | Two-stage LLM Fine-tuning with  Less Specialization and More Generalization |
| 38   | Tuning LayerNorm in Attention: Towards Efficient Multi-Modal LLM  Finetuning (Spotlight) |
| 39   | Octavius: Mitigating Task  Interference in MLLMs via LoRA-MoE |
| 40   | The Unlocking Spell on Base LLMs:  Rethinking Alignment via In-Context Learning |
| 41   | Overcoming the Pitfalls of  Vision-Language Model Finetuning for OOD Generalization |
| 42   | Federated Text-driven Prompt Generation for Vision-Language Models |

## AI4Science

| #    | Title                                                        |
| ---- | ------------------------------------------------------------ |
| 1    | CellPLM:  Pre-training of Cell Language Model Beyond Single  Cells |
| 2    | Most  discriminative stimuli for functional cell  type clustering |
| 3    | BioBridge:  Bridging Biomedical Foundation Models via  Knowledge Graphs |
| 4    | DNABERT-2:  Efficient Foundation Model and  Benchmark For Multi-Species Genomes |
| 5    | DNA-GPT:  Divergent N-Gram Analysis for  Training-Free Detection of GPT-Generated Text |
| 6    | BEND:  Benchmarking DNA Language Models on  Biologically Meaningful Tasks |
| 7    | Protein Discovery with Discrete  Walk-Jump Sampling (Oral,  Outstanding Paper) |
| 8    | Manipulating dropout reveals an optimal  balance of efficiency and robustness in biological and machine visual systems |
| 9    | Learning dynamic representations of the  functional connectome in neurobiological networks |
| 10   | RDesign: Hierarchical Data-efficient  Representation Learning for Tertiary Structure-based RNA Design |
| 11   | Gene  Regulatory Network Inference in the Presence of Dropouts: a Causal View  (Oral) |
| 12   | From Molecules to Materials:  Pre-training Large Generalizable Models for Atomic Property Prediction |
| 13   | Pre-training  Sequence, Structure, and Surface Features for Comprehensive Protein Representation Learning |
| 14   | Sliced  Denoising: A Physics-Informed Molecular  Pre-Training Method |
| 15   | Neuroformer:  Multimodal and Multitask Generative Pretraining for Brain Data |
| 16   | Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large  Language Models |
| 17   | DecompOpt:  Controllable and Decomposed Diffusion Models for Structure-based Molecular Optimization |
| 18   | GeoLLM: Extracting Geospatial Knowledge from Large Language Models |
| 19   | Str2Str:  A Score-based Framework for Zero-shot Protein  Conformation Sampling |
| 20   | Evaluating Representation Learning on  the Protein Structure Universe |
| 21   | EBMDock:  Neural Probabilistic Protein-Protein  Docking via a Differentiable Energy Model |
| 22   | Dynamics-Informed  Protein Design with  Structure Conditioning |
| 23   | Protein-ligand  binding representation learning from fine-grained interactions |
| 24   | Dynamics-Informed  Protein  Design with Structure Conditioning |
| 25   | Multimodal  Molecular Pretraining via  Modality Blending     |
| 26   | De  novo Protein  Design Using Geometric Vector Field Networks (Spotlight) |
| 27   | Improving  protein  optimization with smoothed fitness landscapes |
| 28   | SE(3)-Stochastic  Flow Matching for Protein Backbone  Generation (Spotlight) |
| 29   | MAPE-PPI:  Towards Effective and Efficient Protein-Protein  Interaction Prediction via Microenvironment-Aware Protein Embedding  (Spotlight) |
| 30   | Long-Short-Range Message-Passing: A  Physics-Informed Framework to Capture Non-Local Interaction for Scalable Molecular Dynamics Simulation |
| 31   | Self-supervised  Pocket Pretraining via Protein Fragment-Surroundings  Alignment |
| 32   | Deep Reinforcement Learning for  Modelling Protein Complexes |
| 33   | Protein Multimer Structure Prediction via  Prompt Learning   |
| 34   | Protein-Ligand Interaction Prior for  Binding-aware 3D Molecule Diffusion Models |
| 35   | Improving protein optimization with smoothed  fitness landscapes |
| 36   | KW-Design: Pushing the Limit of Protein Design via Knowledge Refinement |
| 37   | Rigid Protein-Protein Docking via Equivariant  Elliptic-Paraboloid Interface Prediction |
| 38   | SaProt: Protein Language Modeling with Structure-aware Vocabulary  (Spotlight) |

## Multimodal Learning

| #    | Title                                                        |
| ---- | ------------------------------------------------------------ |
| 1    | Quantifying  and Enhancing Multi-modal Robustness with Modality  Preference |
| 2    | Understanding  the Robustness of Multi-modal Contrastive  Learning to Distribution Shift |
| 3    | CLIP  the Bias: How Useful is Balancing Data in  Multimodal Learning? |
| 4    | Multimodal  Learning Without Labeled Multimodal Data: Guarantees and Applications |
| 5    | Multi-modal  Gaussian Process Variational Autoencoders for Neural and  Behavioral Data |
| 6    | Test-time Adaptation against Multi-modal Reliability Bias    |
| 7    | Towards Robust Multi-Modal Reasoning via Model Selection     |
| 8    | MaGIC: Multi-modality Guided Image Completion                |
| 9    | Tuning LayerNorm in Attention: Towards Efficient Multi-Modal LLM  Finetuning (Spotlight) |
| 10   | Towards  Unified Multi-Modal  Personalization: Large Vision-Language Models for  Generative Recommendation and Beyond |
| 11   | MMICL:  Empowering Vision-language Model with Multi-Modal  In-Context Learning |
| 12   | Fine-tuning  Multimodal LLMs to Follow Zero-shot Demonstrative  Instructions (Spotlight) |
| 13   | DV-3DLane:  End-to-end Multi-modal 3D Lane Detection with  Dual-view Representation |
| 14   | Mitigating  Hallucination in Large Multi-Modal Models via  Robust Instruction Tuning |
| 15   | Emu: Generative Pretraining in  Multimodality                |
| 16   | Jailbreak  in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models (Spotlight) |
| 17   | Understanding  the Robustness of Multi-modal Contrastive  Learning to Distribution Shift |
| 18   | Multimodal Patient Representation  Learning with Missing Modalities and Labels |
| 19   | Neuroformer:  Multimodal and Multitask  Generative Pretraining for Brain Data |
| 20   | Neuro-Inspired Information-Theoretic  Hierarchical Perception for Multimodal Learning |
| 21   | Jointly  Training Large Autoregressive Multimodal  Models    |
| 22   | Kosmos-G:  Generating Images in Context with Multimodal  Large Language Models |
| 23   | Guiding  Instruction-based Image Editing via Multimodal  Large Language Models (Spotlight) |
| 24   | Sampling  Multimodal Distributions with the Vanilla Score: Benefits of Data-Based  Initialization |
| 25   | On  the generalization capacity of neural networks during generic multimodal reasoning |
| 26   | Multimodal  Web Navigation with Instruction-Finetuned  Foundation Models |
| 27   | Beyond  task performance: evaluating and reducing the flaws of large multimodal models with  in-context-learning |
| 28   | InternVid:  A Large-scale Video-Text Dataset for Multimodal  Understanding and Generation |
| 29   | Prototypical  Information Bottlenecking and Disentangling for Multimodal Cancer Survival Prediction (Spotlight) |
| 30   | MIntRec2.0:  A Large-scale Benchmark Dataset  for Multimodal Intent Recognition and Out-of-scope Detection in Conversations |
| 31   | Fine-tuning  Multimodal LLMs to Follow Zero-shot Demonstrative  Instructions |
| 32   | Large Multilingual Models Pivot  Zero-Shot Multimodal Learning across Languages (Spotlight) |
| 33   | VDC: Versatile Data Cleanser  based on Visual-Linguistic Inconsistency by Multimodal Large Language  Models |
| 34   | Grounding Multimodal Large Language  Models to  the World    |
| 35   | EQA-MX: Embodied Question  Answering using Multimodal Expression (Spotlight) |
| 36   | Deep Generative Clustering with Multimodal Diffusion  Variational Autoencoders |

## Medical

| #    | Title                                                        |
| ---- | ------------------------------------------------------------ |
| 1    | FairSeg:  A Large-Scale Medical Image Segmentation Dataset for  Fairness Learning Using Segment Anything Model with Fair Error-Bound Scaling |
| 2    | Domain  constraints improve risk prediction when  outcome data is missing |
| 3    | Learning  from Aggregate responses: Instance Level versus Bag Level Loss Functions [MIL] |
| 4    | CAMIL:  Context-Aware Multiple Instance Learning for  Cancer Detection and Subtyping in Whole  Slide Images (Spotlight) |
| 5    | MOTOR:  A Time-to-Event Foundation  Model For Structured Medical Records (Spotlight) |
| 6    | Prototypical  Information Bottlenecking and Disentangling for Multimodal Cancer Survival Prediction (Spotlight) |
| 7    | LLM-CXR: Instruction-Finetuned LLM for CXR Image Understanding and  Generation |
| 8    | Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting |
| 9    | BioBridge: Bridging Biomedical Foundation Models via Knowledge Graphs |
| 10   | How Well Do Supervised 3D Models Transfer to Medical Imaging  Tasks? (Oral) |
| 11   | The  Effect of Intrinsic Dataset Properties on Generalization: Unraveling Learning Differences Between Natural and Medical Images |
| 12   | FairTune:  Optimizing Parameter Efficient Fine Tuning for Fairness  in Medical Image Analysis |

## XAI

| #    | Title                                                        |
| ---- | ------------------------------------------------------------ |
| 1    | Interpreting  CLIP's Image Representation via Text-Based Decomposition  (Oral) |
| 2    | The  Devil is in the Neurons: Interpreting and Mitigating Social Biases in  Language Models |
| 3    | InfoCon:  Concept Discovery with Generative and Discriminative Informativeness |
| 4    | Bootstrapping  Variational Information Pursuit with Large Language and Vision Models for  Interpretable Image Classification |
| 5    | A  Simple Interpretable Transformer for Fine-Grained Image Classification and  Analysis |
| 6    | Tell  Your Model Where to Attend: Post-hoc Attention Steering for LLMs |
| 7    | Harnessing Explanations: LLM-to-LM  Interpreter for Enhanced Text-Attributed Graph Representation Learning |
| 8    | Faithful Explanations of Black-box NLP  Models Using LLM-generated Counterfactuals |
| 9    | Faithful Vision-Language Interpretation  via Concept Bottleneck Models |
| 10   | INViTE: INterpret and Control Vision-Language Models  with Text Explanations |
| 11   | Successor  Heads: Recurring, Interpretable Attention Heads In The Wild |
| 12   | Going  Beyond Neural Network Feature Similarity: The Network Feature Complexity and  Its Interpretation Using Category Theory |
| 13   | Sparse  Autoencoders Find Highly Interpretable Features in Language Models |
| 14   | Tensor Trust: Interpretable Prompt  Injection Attacks from an Online Game (Spotlight) |
| 15   | PRIME:  Prioritizing Interpretability in Failure Mode Extraction |
| 16   | Interpretable  Diffusion via Information Decomposition       |
| 17   | Diffusion-TS:  Interpretable Diffusion for General Time Series Generation |
| 18   | Interpretable  Sparse System Identification: Beyond Recent Deep Learning Techniques on  Time-Series Prediction |
| 19   | "What  Data Benefits My Classifier?" Enhancing Model Performance and  Interpretability through Influence-Based Data Selection (Oral) |
| 20   | Less  is More: Fewer Interpretable Region via Submodular Subset Selection (Oral) |
| 21   | Mediator Interpretation and Faster  Learning Algorithms for Linear Correlated Equilibria in General Sequential  Games |
| 22   | SOInter: A Novel Deep Energy-Based  Interpretation Method for Explaining Structured Output Models |
| 23   | Learning  interpretable control inputs and dynamics underlying animal locomotion |
| 24   | Predictive,  scalable and interpretable knowledge tracing on structured domains |
| 25   | Piecewise  Linear Parametrization of Policies: Towards Interpretable Deep Reinforcement  Learning |
| 26   | Energy-Based  Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and  Probabilistic Interpretations |
| 27   | Interpreting  Robustness Proofs of Deep Neural Networks      |
| 28   | Inherently  Interpretable Time Series Classification via Multiple Instance Learning  (Spotlight) |
| 29   | Respect  the model: Fine-grained and Robust Explanation with Sharing Ratio  Decomposition |
| 30   | UNR-Explainer:  Counterfactual Explanations for Unsupervised Node Representation Learning  Models |
| 31   | AttEXplore:  Attribution for Explanation with model parameters eXploration |
| 32   | RAPPER: Reinforced Rationale-Prompted  Paradigm for Natural Language Explanation in Visual Question Answering |
| 33   | Towards Faithful Explanations:  Boosting Rationalization with Shortcuts Discovery |
| 34   | Causality-Inspired Spatial-Temporal  Explanations for Dynamic Graph Neural Networks |
| 35   | Faithful and Efficient  Explanations for Neural Networks via Neural Tangent Kernel Surrogate Models  (Spotlight) |
| 36   | Language-Informed Visual Concept  Learning                   |
| 37   | Bongard-OpenWorld: Few-Shot Reasoning  for Free-form Visual Concepts in the Real World |
| 38   | Classification with Conceptual  Safeguards                   |
| 39   | Ring-A-Bell! How Reliable are  Concept Removal Methods For Diffusion Models? |
| 40   | Concept Bottleneck Generative  Models                        |
| 41   | Circumventing Concept Erasure  Methods For Text-To-Image Generative Models |

## Safety in AI

| #    | Title                                                        |
| ---- | ------------------------------------------------------------ |
| 1    | Analyzing  and Mitigating Object Hallucination  in Large Vision-Language Models |
| 2    | An  Image Is Worth 1000 Lies: Transferability of Adversarial Images across  Prompts on Vision-Language Models (Spotlight) |
| 3    | INSIDE:  LLMs' Internal States Retain the Power of Hallucination  Detection |
| 4    | Can  LLM-Generated Misinformation  Be Detected?              |
| 5    | Catastrophic  Jailbreak  of Open-source LLMs via Exploiting Generation |
| 6    | An  LLM can Fool Itself: A Prompt-Based Adversarial Attack   |
| 7    | Teach LLMs to Phish: Stealing Private Information from Language Models |
| 8    | Can LLMs Keep a Secret? Testing Privacy Implications of Language Models  via Contextual Integrity Theory (Spotlight) |
| 9    | Can Sensitive Information Be Deleted From LLMs? Objectives  for Defending Against Extraction Attacks (Spotlight) |
| 10   | GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via  Cipher |
| 11   | Don't  Trust: Verify -- Grounding LLM Quantitative Reasoning with Autoformalization |
| 12   | Mitigating  Hallucination  in Large Multi-Modal Models via Robust Instruction Tuning |
| 13   | Jailbreak  in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models (Spotlight) |
